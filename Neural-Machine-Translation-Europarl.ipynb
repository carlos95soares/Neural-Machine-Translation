{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bc0d229",
   "metadata": {},
   "source": [
    "**✅ ETAPA 0 — Parâmetros iniciais**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76316ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definição dos principais parâmetros iniciais\n",
    "\n",
    "# Tamanho do conjunto de treino, validação e teste (Etapa 2)\n",
    "len_train = 60000\n",
    "len_valid = 5000\n",
    "len_test = 5000\n",
    "\n",
    "# Tamanho máximo das sentenças (Etapa 4)\n",
    "MAX_LEN = 35\n",
    "\n",
    "# Tamanho máximo do vocabulário (Etapa 5)\n",
    "max_vocab = 35000\n",
    "\n",
    "# Tokens especiais (Etapa 5)\n",
    "PAD_TOKEN = \"<pad>\"\n",
    "SOS_TOKEN = \"<sos>\"\n",
    "EOS_TOKEN = \"<eos>\"\n",
    "UNK_TOKEN = \"<unk>\"\n",
    "\n",
    "# Tamanho do batch (Etapa 7)\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Dimensões das embeddings e do hidden state (Etapa 8)\n",
    "EMB_DIM = 128\n",
    "HIDDEN_DIM = 256\n",
    "\n",
    "# Número de camadas e dropout para o Encoder e Decoder (Etapa 8)\n",
    "var_num_layers = 1\n",
    "var_dropout = 0.3\n",
    "\n",
    "# Número de épocas e paciência para early stopping (Etapa 10)\n",
    "N_EPOCHS = 15\n",
    "PATIENCE = 3\n",
    "\n",
    "# Taxa de aprendizado (Etapa 10)\n",
    "var_lr = 0.001\n",
    "\n",
    "# Parâmetros para a tradução com Beam Search (Etapa 12)\n",
    "var_repetition_penalty = 0\n",
    "var_beam_width = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44ad8cb",
   "metadata": {},
   "source": [
    "**✅ ETAPA 1 — Download do Europarl EN–PT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b38e7a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Natural_Language_Processing\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Download do dataset de sentenças paralelas Europarl (Inglês-Português)\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\n",
    "    \"sentence-transformers/parallel-sentences-europarl\",\n",
    "    \"en-pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c13c16dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\Carlos\n",
      "[nltk_data]     Soares\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to C:\\Users\\Carlos\n",
      "[nltk_data]     Soares\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imports necessários\n",
    "import torch\n",
    "import re\n",
    "import random\n",
    "from collections import Counter\n",
    "from torch.utils.data import Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import nltk\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cf099c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Configurando o dispositivo para treinamento (GPU se disponível)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbbb14a",
   "metadata": {},
   "source": [
    "**✅ ETAPA 2 — Inspeção + Amostragem do Europarl EN–PT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a93030e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['train'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Conferindo o conteúdo do dataset\n",
    "dataset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d74a2ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'english': 'Resumption of the session', 'non_english': 'Reinício da sessão'}\n"
     ]
    }
   ],
   "source": [
    "# Conferindo a primeira amostra do conjunto de treino\n",
    "print(dataset[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81d4e5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embaralhando e criando subconjuntos menores para treino, validação e teste\n",
    "dataset_shuffled = dataset[\"train\"].shuffle(seed=42)\n",
    "\n",
    "dataset_small = {\n",
    "    \"train\": dataset_shuffled.select(range(0, len_train)),\n",
    "    \"validation\": dataset_shuffled.select(range(len_train, len_train + len_valid)),\n",
    "    \"test\": dataset_shuffled.select(range(len_train + len_valid, len_train + len_valid + len_test)),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94c7ebe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 60000\n",
      "validation 5000\n",
      "test 5000\n"
     ]
    }
   ],
   "source": [
    "# Conferindo o tamanho dos novos subconjuntos\n",
    "for split in dataset_small:\n",
    "    print(split, len(dataset_small[split]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "462f5660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EN: It is not enough to enable them to get the hang of the programmes and the management structures as well, and then require only 3500 posts up to 2008, all of which is described as 'enlargement costs'.\n",
      "PT: O facto de se autorizar um alargamento dos programas e também das estruturas administrativas, e apenas se exigir a criação de 3 500 novos lugares até 2008, que será designado como o custo do alargamento, parece naturalmente muito pouco.\n"
     ]
    }
   ],
   "source": [
    "# Conferindo uma amostra do conjunto de treino\n",
    "sample = dataset_small[\"train\"][0]\n",
    "print(\"EN:\", sample[\"english\"])\n",
    "print(\"PT:\", sample[\"non_english\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fe673d",
   "metadata": {},
   "source": [
    "**✅ ETAPA 3 — Limpeza mínima de texto (controlada)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "873e0389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função de pré-processamento de texto (convertendo para minúsculas e removendo espaços extras)\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    text = text.strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "405d779c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando o pré-processamento ao dataset\n",
    "def preprocess(example):\n",
    "    return {\n",
    "        \"en\": clean_text(example[\"english\"]),\n",
    "        \"pt\": clean_text(example[\"non_english\"])\n",
    "    }\n",
    "\n",
    "dataset_clean = {}\n",
    "\n",
    "for split in dataset_small:\n",
    "    dataset_clean[split] = dataset_small[split].map(\n",
    "        preprocess,\n",
    "        remove_columns=[\"english\", \"non_english\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b169867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANTES:\n",
      "{'english': \"It is not enough to enable them to get the hang of the programmes and the management structures as well, and then require only 3500 posts up to 2008, all of which is described as 'enlargement costs'.\", 'non_english': 'O facto de se autorizar um alargamento dos programas e também das estruturas administrativas, e apenas se exigir a criação de 3 500 novos lugares até 2008, que será designado como o custo do alargamento, parece naturalmente muito pouco.'}\n",
      "\n",
      "DEPOIS:\n",
      "{'en': \"it is not enough to enable them to get the hang of the programmes and the management structures as well, and then require only 3500 posts up to 2008, all of which is described as 'enlargement costs'.\", 'pt': 'o facto de se autorizar um alargamento dos programas e também das estruturas administrativas, e apenas se exigir a criação de 3 500 novos lugares até 2008, que será designado como o custo do alargamento, parece naturalmente muito pouco.'}\n"
     ]
    }
   ],
   "source": [
    "# Conferindo uma amostra do conjunto de treino antes e depois do pré-processamento\n",
    "print(\"ANTES:\")\n",
    "print(dataset_small[\"train\"][0])\n",
    "\n",
    "print(\"\\nDEPOIS:\")\n",
    "print(dataset_clean[\"train\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cef176e",
   "metadata": {},
   "source": [
    "**✅ ETAPA 4 — Filtrar frases vazias e muito longas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c880787e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando função para filtrar sentenças muito longas ou vazias\n",
    "def length_filter(example):\n",
    "    return (\n",
    "        len(example[\"en\"].split()) > 0 and\n",
    "        len(example[\"pt\"].split()) > 0 and\n",
    "        len(example[\"en\"].split()) <= MAX_LEN and\n",
    "        len(example[\"pt\"].split()) <= MAX_LEN\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1bcf7f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrando o dataset\n",
    "dataset_filtered = {}\n",
    "\n",
    "for split in dataset_clean:\n",
    "    dataset_filtered[split] = dataset_clean[split].filter(length_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c013a205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train antes: 60000 depois: 45307\n",
      "validation antes: 5000 depois: 3790\n",
      "test antes: 5000 depois: 3733\n"
     ]
    }
   ],
   "source": [
    "# Conferindo o tamanho dos datasets antes e depois da filtragem\n",
    "for split in dataset_clean:\n",
    "    print(\n",
    "        split,\n",
    "        \"antes:\", len(dataset_clean[split]),\n",
    "        \"depois:\", len(dataset_filtered[split])\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5464ca32",
   "metadata": {},
   "source": [
    "**✅ ETAPA 5 — Construção do vocabulário (word-level)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c6d40072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construindo vocabulários para inglês e português\n",
    "def build_vocab(sentences, max_vocab_size=max_vocab):\n",
    "    counter = Counter()\n",
    "\n",
    "    for sent in sentences:\n",
    "        counter.update(sent.split())\n",
    "\n",
    "    vocab = {\n",
    "        PAD_TOKEN: 0,\n",
    "        SOS_TOKEN: 1,\n",
    "        EOS_TOKEN: 2,\n",
    "        UNK_TOKEN: 3,\n",
    "    }\n",
    "\n",
    "    for word, _ in counter.most_common(max_vocab_size - len(vocab)):\n",
    "        vocab[word] = len(vocab)\n",
    "\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bf928143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construindo os vocabulários\n",
    "en_vocab = build_vocab(dataset_filtered[\"train\"][\"en\"])\n",
    "pt_vocab = build_vocab(dataset_filtered[\"train\"][\"pt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1783db55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EN vocab size: 35000\n",
      "PT vocab size: 35000\n"
     ]
    }
   ],
   "source": [
    "# Conferindo o tamanho dos vocabulários\n",
    "print(\"EN vocab size:\", len(en_vocab))\n",
    "print(\"PT vocab size:\", len(pt_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e5a4b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i wish to make four points.\n",
      "[13, 240, 6, 89, 602, 1281]\n"
     ]
    }
   ],
   "source": [
    "# Conferindo uma amostra do conjunto de treino e sua representação numérica\n",
    "sample = dataset_filtered[\"train\"][0][\"en\"]\n",
    "print(sample)\n",
    "print([en_vocab.get(tok, en_vocab[UNK_TOKEN]) for tok in sample.split()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfd886f",
   "metadata": {},
   "source": [
    "**✅ ETAPA 6 — Encoding das frases + Dataset PyTorch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "db35fe00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para converter sentenças em sequências de índices, incluindo tokens especiais\n",
    "def encode_sentence(sentence, vocab):\n",
    "    tokens = sentence.split()\n",
    "    return (\n",
    "        [vocab[SOS_TOKEN]] +\n",
    "        [vocab.get(tok, vocab[UNK_TOKEN]) for tok in tokens] +\n",
    "        [vocab[EOS_TOKEN]]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "365ed6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando a codificação ao dataset\n",
    "def encode_example(example):\n",
    "    return {\n",
    "        \"en_ids\": encode_sentence(example[\"en\"], en_vocab),\n",
    "        \"pt_ids\": encode_sentence(example[\"pt\"], pt_vocab),\n",
    "    }\n",
    "\n",
    "dataset_encoded = {}\n",
    "\n",
    "for split in dataset_filtered:\n",
    "    dataset_encoded[split] = dataset_filtered[split].map(encode_example)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a39c115a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EN texto: i wish to make four points.\n",
      "EN ids: [1, 13, 240, 6, 89, 602, 1281, 2]\n",
      "PT texto: gostaria de focar quatro aspectos.\n",
      "PT ids: [1, 55, 4, 4652, 659, 2890, 2]\n"
     ]
    }
   ],
   "source": [
    "# Conferindo uma amostra do conjunto de treino codificado\n",
    "sample = dataset_encoded[\"train\"][0]\n",
    "\n",
    "print(\"EN texto:\", dataset_filtered[\"train\"][0][\"en\"])\n",
    "print(\"EN ids:\", sample[\"en_ids\"])\n",
    "\n",
    "print(\"PT texto:\", dataset_filtered[\"train\"][0][\"pt\"])\n",
    "print(\"PT ids:\", sample[\"pt_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "09afa24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando uma classe Dataset personalizada para PyTorch\n",
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, hf_dataset):\n",
    "        self.data = hf_dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"src\": torch.tensor(self.data[idx][\"en_ids\"], dtype=torch.long),\n",
    "            \"tgt\": torch.tensor(self.data[idx][\"pt_ids\"], dtype=torch.long),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "351f4b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando instâncias dos datasets para PyTorch\n",
    "train_dataset = TranslationDataset(dataset_encoded[\"train\"])\n",
    "val_dataset   = TranslationDataset(dataset_encoded[\"validation\"])\n",
    "test_dataset  = TranslationDataset(dataset_encoded[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4962bf70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([   1,   13,  240,    6,   89,  602, 1281,    2])\n",
      "tensor([   1,   55,    4, 4652,  659, 2890,    2])\n"
     ]
    }
   ],
   "source": [
    "# Conferindo uma amostra do conjunto de treino PyTorch\n",
    "sample = train_dataset[0]\n",
    "print(sample[\"src\"])\n",
    "print(sample[\"tgt\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8922d83d",
   "metadata": {},
   "source": [
    "**✅ ETAPA 7 — collate_fn + DataLoader (padding correto)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "842eacac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função de colagem para DataLoader do PyTorch\n",
    "def collate_fn(batch):\n",
    "    src_batch = [item[\"src\"] for item in batch]\n",
    "    tgt_batch = [item[\"tgt\"] for item in batch]\n",
    "\n",
    "    src_padded = pad_sequence(\n",
    "        src_batch,\n",
    "        batch_first=True,\n",
    "        padding_value=en_vocab[PAD_TOKEN]\n",
    "    )\n",
    "\n",
    "    tgt_padded = pad_sequence(\n",
    "        tgt_batch,\n",
    "        batch_first=True,\n",
    "        padding_value=pt_vocab[PAD_TOKEN]\n",
    "    )\n",
    "\n",
    "    return src_padded, tgt_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ce62d0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando DataLoaders para treino, validação e teste\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc72605",
   "metadata": {},
   "source": [
    "**✅ ETAPA 8 — Implementação do Encoder (LSTM)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f43bd461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando a classe Encoder usando LSTM em PyTorch\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hidden_dim, num_layers=var_num_layers, dropout=var_dropout):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embeddings=input_dim,\n",
    "            embedding_dim=emb_dim,\n",
    "            padding_idx=en_vocab[PAD_TOKEN]\n",
    "        )\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=emb_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0\n",
    "        )\n",
    "\n",
    "    def forward(self, src):\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        encoder_outputs, (hidden, cell) = self.lstm(embedded)\n",
    "        \n",
    "        return encoder_outputs, hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8a5ae52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando uma instância do Encoder\n",
    "INPUT_DIM = len(en_vocab)\n",
    "# EMB_DIM definidio anteriormente\n",
    "# HIDDEN_DIM definidio anteriormente\n",
    "\n",
    "encoder = Encoder(\n",
    "    input_dim=INPUT_DIM,\n",
    "    emb_dim=EMB_DIM,\n",
    "    hidden_dim=HIDDEN_DIM\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cd57b2e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_outputs: torch.Size([64, 37, 256]) cuda:0\n",
      "hidden: torch.Size([1, 64, 256]) cuda:0\n",
      "cell: torch.Size([1, 64, 256]) cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Testando o Encoder com um batch de dados\n",
    "src, tgt = next(iter(train_loader))\n",
    "src = src.to(device)\n",
    "tgt = tgt.to(device)\n",
    "\n",
    "encoder = encoder.to(device)\n",
    "\n",
    "encoder_outputs, hidden, cell = encoder(src)\n",
    "\n",
    "print(\"encoder_outputs:\", encoder_outputs.shape, encoder_outputs.device)\n",
    "print(\"hidden:\", hidden.shape, hidden.device)\n",
    "print(\"cell:\", cell.shape, cell.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5070c426",
   "metadata": {},
   "source": [
    "**✅ ETAPA 8.1 — Implementação do Attention**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "44bc69b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando a classe de Atenção Bahdanau em PyTorch\n",
    "class BahdanauAttention(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.attn = nn.Linear(hidden_dim * 2, hidden_dim)\n",
    "        self.v = nn.Linear(hidden_dim, 1, bias=False)\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        src_len = encoder_outputs.size(1)\n",
    "\n",
    "        # Repetir hidden para cada timestep do encoder\n",
    "        hidden = hidden.permute(1, 0, 2)              # [batch, 1, hidden]\n",
    "        hidden = hidden.repeat(1, src_len, 1)         # [batch, src_len, hidden]\n",
    "\n",
    "        # Concatenar hidden do decoder com outputs do encoder\n",
    "        energy = torch.tanh(\n",
    "            self.attn(torch.cat((hidden, encoder_outputs), dim=2))\n",
    "        )                                              # [batch, src_len, hidden]\n",
    "\n",
    "        # Calcular scores\n",
    "        attention = self.v(energy).squeeze(2)         # [batch, src_len]\n",
    "\n",
    "        # Softmax para obter pesos\n",
    "        attention_weights = torch.softmax(attention, dim=1)\n",
    "\n",
    "        # Context vector = soma ponderada\n",
    "        context = torch.bmm(\n",
    "            attention_weights.unsqueeze(1),\n",
    "            encoder_outputs\n",
    "        ).squeeze(1)                                   # [batch, hidden]\n",
    "\n",
    "        return context, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4207a3f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context: torch.Size([64, 256])\n",
      "attn_weights: torch.Size([64, 37])\n"
     ]
    }
   ],
   "source": [
    "# Testando a Atenção Bahdanau com saídas do Encoder\n",
    "attention = BahdanauAttention(HIDDEN_DIM).to(device)\n",
    "\n",
    "src, tgt = next(iter(train_loader))\n",
    "src = src.to(device)\n",
    "\n",
    "encoder_outputs, hidden, cell = encoder(src)\n",
    "\n",
    "context, attn_weights = attention(hidden, encoder_outputs)\n",
    "\n",
    "print(\"context:\", context.shape)\n",
    "print(\"attn_weights:\", attn_weights.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ee2bfe",
   "metadata": {},
   "source": [
    "**✅ ETAPA 9 — Implementação do Decoder (LSTM + Teacher Forcing)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c23056cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando a classe Decoder usando LSTM em PyTorch\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hidden_dim, attention, dropout=0.3):\n",
    "        super().__init__()\n",
    "\n",
    "        self.output_dim = output_dim\n",
    "        self.attention = attention\n",
    "\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            emb_dim + hidden_dim,\n",
    "            hidden_dim,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        self.fc_out = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, input, hidden, cell, encoder_outputs):\n",
    "        input = input.unsqueeze(1)\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "\n",
    "        context, attention_weights = self.attention(hidden, encoder_outputs)\n",
    "        context = context.unsqueeze(1)\n",
    "\n",
    "        lstm_input = torch.cat((embedded, context), dim=2)\n",
    "        output, (hidden, cell) = self.lstm(lstm_input, (hidden, cell))\n",
    "\n",
    "        prediction = self.fc_out(output.squeeze(1))\n",
    "\n",
    "        return prediction, hidden, cell, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bffeefb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: torch.Size([64, 35000])\n",
      "attn_weights: torch.Size([64, 35])\n"
     ]
    }
   ],
   "source": [
    "# Criando uma instância do Decoder\n",
    "attention = BahdanauAttention(HIDDEN_DIM).to(device)\n",
    "decoder = Decoder(len(pt_vocab), EMB_DIM, HIDDEN_DIM, attention).to(device)\n",
    "\n",
    "src, tgt = next(iter(train_loader))\n",
    "src = src.to(device)\n",
    "tgt = tgt.to(device)\n",
    "\n",
    "encoder_outputs, hidden, cell = encoder(src)\n",
    "\n",
    "input_token = tgt[:, 0]  # <sos>\n",
    "\n",
    "output, hidden, cell, attn_weights = decoder(\n",
    "    input_token,\n",
    "    hidden,\n",
    "    cell,\n",
    "    encoder_outputs\n",
    ")\n",
    "\n",
    "print(\"output:\", output.shape)\n",
    "print(\"attn_weights:\", attn_weights.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3fa046",
   "metadata": {},
   "source": [
    "**✅ ETAPA 10 — Classe Seq2Seq + Loop de Treino (Teacher Forcing)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6e89b6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando a classe Seq2Seq combinando Encoder e Decoder\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, src, tgt, teacher_forcing_ratio=0.5):\n",
    "        batch_size = src.size(0)\n",
    "        tgt_len = tgt.size(1)\n",
    "        tgt_vocab_size = self.decoder.output_dim\n",
    "\n",
    "        outputs = torch.zeros(\n",
    "            batch_size,\n",
    "            tgt_len,\n",
    "            tgt_vocab_size\n",
    "        ).to(self.device)\n",
    "\n",
    "        encoder_outputs, hidden, cell = self.encoder(src)\n",
    "\n",
    "        input = tgt[:, 0]  # <sos>\n",
    "\n",
    "        for t in range(1, tgt_len):\n",
    "            output, hidden, cell, _ = self.decoder(\n",
    "                input,\n",
    "                hidden,\n",
    "                cell,\n",
    "                encoder_outputs\n",
    "            )\n",
    "\n",
    "            outputs[:, t] = output\n",
    "\n",
    "            teacher_force = torch.rand(1).item() < teacher_forcing_ratio\n",
    "            top1 = output.argmax(1)\n",
    "\n",
    "            input = tgt[:, t] if teacher_force else top1\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b4f4f106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando uma instância do modelo Seq2Seq\n",
    "model = Seq2Seq(encoder, decoder, device).to(device)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=pt_vocab[PAD_TOKEN])\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=var_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797ceb7d",
   "metadata": {},
   "source": [
    "**✅ ETAPA 11 — Treinamento do modelo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8580e2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função de treinamento para uma época\n",
    "def train_epoch(model, dataloader, optimizer, criterion, clip=1.0):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for src, tgt in dataloader:\n",
    "        src = src.to(device)\n",
    "        tgt = tgt.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(src, tgt)\n",
    "        output_dim = output.shape[-1]\n",
    "\n",
    "        output = output[:, 1:].reshape(-1, output_dim)\n",
    "        tgt = tgt[:, 1:].reshape(-1)\n",
    "\n",
    "        loss = criterion(output, tgt)\n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ac3e975c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para traduzir uma sentença usando beam search\n",
    "def translate_sentence_beam(\n",
    "    sentence,\n",
    "    src_vocab,\n",
    "    tgt_vocab,\n",
    "    model,\n",
    "    device,\n",
    "    max_len=40,\n",
    "    beam_width=5,\n",
    "    repetition_penalty=1.2\n",
    "):\n",
    "    model.eval()\n",
    "    \n",
    "    # Codificar sentença source\n",
    "    tokens = sentence.lower().split()\n",
    "    src_indexes = (\n",
    "        [src_vocab[\"<sos>\"]] +\n",
    "        [src_vocab.get(tok, src_vocab[\"<unk>\"]) for tok in tokens] +\n",
    "        [src_vocab[\"<eos>\"]]\n",
    "    )\n",
    "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        encoder_outputs, hidden, cell = model.encoder(src_tensor)\n",
    "    \n",
    "    # Inicializar beam com <sos>\n",
    "    beams = [(\n",
    "        [tgt_vocab[\"<sos>\"]],  # sequência\n",
    "        0.0,                    # score acumulado\n",
    "        hidden,                 # hidden state\n",
    "        cell                    # cell state\n",
    "    )]\n",
    "    \n",
    "    completed = []\n",
    "    \n",
    "    for _ in range(max_len):\n",
    "        all_candidates = []\n",
    "        \n",
    "        for seq, score, h, c in beams:\n",
    "            # Se já terminou, adiciona aos completos\n",
    "            if seq[-1] == tgt_vocab[\"<eos>\"]:\n",
    "                completed.append((seq, score))\n",
    "                continue\n",
    "            \n",
    "            # Próximo token\n",
    "            tgt_tensor = torch.LongTensor([seq[-1]]).to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                output, new_h, new_c, _ = model.decoder(\n",
    "                    tgt_tensor,\n",
    "                    h,\n",
    "                    c,\n",
    "                    encoder_outputs\n",
    "                )\n",
    "            \n",
    "            # Top-k probabilidades\n",
    "            log_probs = torch.log_softmax(output, dim=1)\n",
    "\n",
    "            for token_id in set(seq):  # Tokens já usados\n",
    "                if token_id < log_probs.size(1):\n",
    "                    log_probs[0, token_id] /= repetition_penalty\n",
    "\n",
    "            topk_probs, topk_indices = torch.topk(log_probs, beam_width)\n",
    "            \n",
    "            # Criar candidatos\n",
    "            for i in range(beam_width):\n",
    "                token = topk_indices[0, i].item()\n",
    "                token_score = topk_probs[0, i].item()\n",
    "                \n",
    "                new_seq = seq + [token]\n",
    "                new_score = score + token_score\n",
    "                \n",
    "                all_candidates.append((new_seq, new_score, new_h, new_c))\n",
    "        \n",
    "        # Selecionar top-k beams\n",
    "        beams = sorted(all_candidates, key=lambda x: x[1], reverse=True)[:beam_width]\n",
    "        \n",
    "        # Se todos completaram, para\n",
    "        if len(completed) >= beam_width:\n",
    "            break\n",
    "    \n",
    "    # Adicionar beams não terminados aos completos\n",
    "    for seq, score, _, _ in beams:\n",
    "        if seq[-1] != tgt_vocab[\"<eos>\"]:\n",
    "            completed.append((seq, score))\n",
    "    \n",
    "    # Escolher melhor sequência (normalizado pelo tamanho)\n",
    "    if not completed:\n",
    "        best_seq = beams[0][0]\n",
    "    else:\n",
    "        best_seq = max(completed, key=lambda x: x[1] / len(x[0]))[0]\n",
    "    \n",
    "    # Converter para palavras\n",
    "    tgt_vocab_inv = {v: k for k, v in tgt_vocab.items()}\n",
    "    tgt_tokens = [\n",
    "        tgt_vocab_inv[idx]\n",
    "        for idx in best_seq\n",
    "        if idx not in (\n",
    "            tgt_vocab[\"<sos>\"],\n",
    "            tgt_vocab[\"<eos>\"],\n",
    "            tgt_vocab[\"<pad>\"]\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    return \" \".join(tgt_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7209b8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função de avaliação usando BLEUScore\n",
    "def calculate_bleu(model, dataset, src_vocab, tgt_vocab, device, num_samples=100):\n",
    "        \n",
    "    model.eval()\n",
    "    references = []\n",
    "    hypotheses = []\n",
    "    \n",
    "    # Vocabulário invertido\n",
    "    src_vocab_inv = {v: k for k, v in src_vocab.items()}\n",
    "    tgt_vocab_inv = {v: k for k, v in tgt_vocab.items()}\n",
    "    \n",
    "    for i in range(min(num_samples, len(dataset))):\n",
    "        sample = dataset[i]\n",
    "        \n",
    "        # Reconstruir sentença source\n",
    "        src_tokens = [src_vocab_inv[idx] for idx in sample['en_ids'] \n",
    "                      if idx not in [src_vocab['<sos>'], src_vocab['<eos>'], src_vocab['<pad>']]]\n",
    "        src_sentence = \" \".join(src_tokens)\n",
    "        \n",
    "        # Referência (tradução correta)\n",
    "        ref_tokens = [tgt_vocab_inv[idx] for idx in sample['pt_ids']\n",
    "                      if idx not in [tgt_vocab['<sos>'], tgt_vocab['<eos>'], tgt_vocab['<pad>']]]\n",
    "        \n",
    "        # Tradução do modelo\n",
    "        translation = translate_sentence_beam(src_sentence, src_vocab, tgt_vocab, model, device)\n",
    "        \n",
    "        references.append([ref_tokens])\n",
    "        hypotheses.append(translation.split())\n",
    "    \n",
    "    return corpus_bleu(references, hypotheses) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fa64b576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função de avaliação usando METEOR\n",
    "def calculate_meteor(model, dataset, src_vocab, tgt_vocab, device, num_samples=100):\n",
    "    model.eval()\n",
    "    scores = []\n",
    "    \n",
    "    # Vocabulário invertido\n",
    "    src_vocab_inv = {v: k for k, v in src_vocab.items()}\n",
    "    tgt_vocab_inv = {v: k for k, v in tgt_vocab.items()}\n",
    "    \n",
    "    for i in range(min(num_samples, len(dataset))):\n",
    "        sample = dataset[i]\n",
    "        \n",
    "        # Reconstruir sentença source\n",
    "        src_tokens = [src_vocab_inv[idx] for idx in sample['en_ids'] \n",
    "                      if idx not in [src_vocab['<sos>'], src_vocab['<eos>'], src_vocab['<pad>']]]\n",
    "        src_sentence = \" \".join(src_tokens)\n",
    "        \n",
    "        # Referência\n",
    "        ref_tokens = [tgt_vocab_inv[idx] for idx in sample['pt_ids']\n",
    "                      if idx not in [tgt_vocab['<sos>'], tgt_vocab['<eos>'], tgt_vocab['<pad>']]]\n",
    "        \n",
    "        # Tradução\n",
    "        translation = translate_sentence_beam(src_sentence, src_vocab, tgt_vocab, model, device)\n",
    "        \n",
    "        # METEOR espera lista de tokens\n",
    "        score = meteor_score([ref_tokens], translation.split())\n",
    "        scores.append(score)\n",
    "    \n",
    "    return sum(scores) / len(scores) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0e3fb50a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Modelo salvo\n",
      "Epoch 1/15 | Train: 6.902 | Val: 6.521 | Time: 365.1s\n",
      "✓ Modelo salvo\n",
      "Epoch 2/15 | Train: 6.211 | Val: 6.265 | Time: 365.2s\n",
      "✓ Modelo salvo\n",
      "Epoch 3/15 | Train: 5.831 | Val: 6.048 | Time: 362.3s\n",
      "✓ Modelo salvo\n",
      "Epoch 4/15 | Train: 5.547 | Val: 5.943 | Time: 362.0s\n",
      "✓ Modelo salvo\n",
      "Epoch 5/15 | Train: 5.324 | Val: 5.863 | Time: 362.1s\n",
      "✓ Modelo salvo\n",
      "Epoch 6/15 | Train: 5.130 | Val: 5.806 | Time: 368.6s\n",
      "✓ Modelo salvo\n",
      "Epoch 7/15 | Train: 4.955 | Val: 5.741 | Time: 367.3s\n",
      "✓ Modelo salvo\n",
      "Epoch 8/15 | Train: 4.793 | Val: 5.723 | Time: 364.4s\n",
      "✓ Modelo salvo\n",
      "Epoch 9/15 | Train: 4.651 | Val: 5.717 | Time: 365.0s\n",
      "✓ Modelo salvo\n",
      "Epoch 10/15 | Train: 4.527 | Val: 5.701 | Time: 364.6s\n",
      "✓ Modelo salvo\n",
      "Epoch 11/15 | Train: 4.408 | Val: 5.681 | Time: 385.9s\n",
      "✓ Modelo salvo\n",
      "Epoch 12/15 | Train: 4.297 | Val: 5.636 | Time: 385.3s\n",
      "Epoch 13/15 | Train: 4.185 | Val: 5.693 | Time: 388.9s\n",
      "Epoch 14/15 | Train: 4.109 | Val: 5.650 | Time: 378.1s\n",
      "Epoch 15/15 | Train: 3.996 | Val: 5.687 | Time: 371.0s\n",
      "\n",
      "Early stopping após 15 épocas\n"
     ]
    }
   ],
   "source": [
    "# Função de validação\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "\n",
    "def eval_epoch(model, dataloader, criterion):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for src, tgt in dataloader:\n",
    "            src = src.to(device)\n",
    "            tgt = tgt.to(device)\n",
    "            \n",
    "            output = model(src, tgt, teacher_forcing_ratio=0)\n",
    "            \n",
    "            output_dim = output.shape[-1]\n",
    "            output = output[:, 1:].reshape(-1, output_dim)\n",
    "            tgt = tgt[:, 1:].reshape(-1)\n",
    "            \n",
    "            loss = criterion(output, tgt)\n",
    "            epoch_loss += loss.item()\n",
    "    \n",
    "    return epoch_loss / len(dataloader)\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    start = time.time()\n",
    "    \n",
    "    train_loss = train_epoch(model, train_loader, optimizer, criterion)\n",
    "    val_loss = eval_epoch(model, val_loader, criterion)\n",
    "    \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), 'best_model.pt')\n",
    "        print(\"✓ Modelo salvo\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "    \n",
    "    print(\n",
    "        f\"Epoch {epoch+1}/{N_EPOCHS} | \"\n",
    "        f\"Train: {train_loss:.3f} | Val: {val_loss:.3f} | \"\n",
    "        f\"Time: {time.time()-start:.1f}s\"\n",
    "    )\n",
    "    \n",
    "    if patience_counter >= PATIENCE:\n",
    "        print(f\"\\nEarly stopping após {epoch+1} épocas\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2a21e754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score: 10.36\n",
      "METEOR Score: 27.01\n"
     ]
    }
   ],
   "source": [
    "# Carregar melhor modelo e calcular métricas\n",
    "model.load_state_dict(torch.load('best_model.pt'))\n",
    "bleu = calculate_bleu(model, dataset_encoded['test'], en_vocab, pt_vocab, device)\n",
    "meteor = calculate_meteor(model, dataset_encoded['test'], en_vocab, pt_vocab, device)\n",
    "\n",
    "print(f\"BLEU Score: {bleu:.2f}\")\n",
    "print(f\"METEOR Score: {meteor:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0cc24d",
   "metadata": {},
   "source": [
    "**✅ ETAPA 12 — Função de Inferência (Greedy Decoding)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b81f6d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Traduções com Beam Search ===\n",
      "\n",
      "EN: i support this proposal\n",
      "PT: por esta proposta de resolução.\n",
      "\n",
      "EN: the report is very important\n",
      "PT: o relatório é muito importante.\n",
      "\n",
      "EN: we must take action now\n",
      "PT: temos de tomar agora a avançar.\n",
      "\n",
      "EN: i voted for this report\n",
      "PT: votei a favor deste relatório.\n",
      "\n",
      "EN: the commission should act\n",
      "PT: a comissão deve <unk>\n",
      "\n",
      "EN: this is a good report\n",
      "PT: trata-se de um relatório <unk>\n",
      "\n",
      "EN: we need more time\n",
      "PT: precisamos de mais\n",
      "\n",
      "EN: the situation is serious\n",
      "PT: a situação <unk>\n",
      "\n",
      "EN: i thank the rapporteur\n",
      "PT: agradeço ao relator\n",
      "\n",
      "EN: we have to work together\n",
      "PT: temos de trabalhar em conjunto.\n",
      "\n",
      "EN: we need economic growth\n",
      "PT: precisamos de crescimento económico.\n",
      "\n",
      "EN: human rights are important\n",
      "PT: os direitos humanos são importantes.\n",
      "\n",
      "EN: climate change is a problem\n",
      "PT: as alterações climáticas é um problema problema.\n",
      "\n",
      "EN: the budget must be approved\n",
      "PT: o orçamento deve ser\n",
      "\n",
      "EN: member states should cooperate\n",
      "PT: os estados-membros devem ser\n",
      "\n",
      "EN: good morning\n",
      "PT: a senhora deputada <unk>\n",
      "\n",
      "EN: hello world\n",
      "PT: no mundo mundial.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Invertendo o vocabulário de português para mapeamento índice -> token\n",
    "src_vocab = en_vocab\n",
    "tgt_vocab = pt_vocab\n",
    "tgt_vocab_inv = {v: k for k, v in tgt_vocab.items()}\n",
    "\n",
    "test_sentences_europarl = [\n",
    "    # Frases curtas e comuns\n",
    "    \"i support this proposal\",\n",
    "    \"the report is very important\",\n",
    "    \"we must take action now\",\n",
    "    \"i voted for this report\",\n",
    "    \"the commission should act\",\n",
    "    \n",
    "    # Estruturas típicas do Europarl\n",
    "    \"this is a good report\",\n",
    "    \"we need more time\",\n",
    "    \"the situation is serious\",\n",
    "    \"i thank the rapporteur\",\n",
    "    \"we have to work together\",\n",
    "    \n",
    "    # Frases sobre política/economia (domínio do dataset)\n",
    "    \"we need economic growth\",\n",
    "    \"human rights are important\",\n",
    "    \"climate change is a problem\",\n",
    "    \"the budget must be approved\",\n",
    "    \"member states should cooperate\",\n",
    "\n",
    "    # Frases fora do domínio (desafio extra)\n",
    "    \"good morning\",\n",
    "    \"hello world\"\n",
    "]\n",
    "\n",
    "print(\"=== Traduções com Beam Search ===\\n\")\n",
    "for sentence in test_sentences_europarl:\n",
    "    translation = translate_sentence_beam(\n",
    "        sentence,\n",
    "        src_vocab,\n",
    "        tgt_vocab,\n",
    "        model,\n",
    "        device,\n",
    "        beam_width=var_beam_width,\n",
    "        repetition_penalty=var_repetition_penalty\n",
    "    )\n",
    "    print(f\"EN: {sentence}\")\n",
    "    print(f\"PT: {translation}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
